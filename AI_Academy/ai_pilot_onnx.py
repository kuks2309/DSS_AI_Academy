#ai_pilot_onnx.py

import sys
import time
import asyncio
import cv2
import numpy as np
import json
import signal
import logging
import os
from pathlib import Path
import time

# ONNX Runtime import
import onnxruntime as ort

# DSS SDK ê´€ë ¨ import
from dss_sdk.core.idsssdk import IDSSSDK
from dss_sdk.config.sdk_config import *
from dss_sdk.core.osi_manager import OSIManager
from dss_sdk.protobuf import dss_pb2

# =============== ë¡œê·¸ ë ˆë²¨ ì„¤ì • ===============
logging.getLogger().setLevel(logging.CRITICAL)
logging.getLogger('nats').setLevel(logging.CRITICAL)
logging.getLogger('asyncio').setLevel(logging.CRITICAL)
logging.getLogger('DSSSDK_PY').setLevel(logging.CRITICAL)
logging.disable(logging.CRITICAL)

class SuppressOutput:
    def __enter__(self):
        self._original_stdout = sys.stdout
        self._original_stderr = sys.stderr
        sys.stdout = open(os.devnull, 'w')
        sys.stderr = open(os.devnull, 'w')
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        sys.stdout.close()
        sys.stderr.close()
        sys.stdout = self._original_stdout
        sys.stderr = self._original_stderr

class YOLOv8ONNXLaneDetector:
    def __init__(self, model_path, conf_threshold=0.01):
        """
        YOLOv8 ONNX ì°¨ì„  ê°ì§€ í´ë˜ìŠ¤ (AI Pilotìš©)
        
        Args:
            model_path (str): ONNX ëª¨ë¸ ê²½ë¡œ
            conf_threshold (float): ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        self.model_path = model_path
        self.conf_threshold = conf_threshold
        self.session = None
        self.input_name = None
        self.output_names = None
        self.load_model()
        
        # ì„±ëŠ¥ ì¸¡ì • ë³€ìˆ˜
        self.inference_times = []
        self.max_inference_history = 30
    
    def load_model(self):
        """ONNX ëª¨ë¸ ë¡œë“œ"""
        try:
            if not os.path.exists(self.model_path):
                print(f"âŒ ONNX ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
                return False
            
            print(f"ğŸ“¥ YOLOv8 ONNX ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_path}")
            
            # ONNX Runtime ì„¸ì…˜ ìƒì„±
            self.session = ort.InferenceSession(self.model_path, providers=['CPUExecutionProvider'])
            
            # ì…ì¶œë ¥ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            self.input_name = self.session.get_inputs()[0].name
            self.output_names = [output.name for output in self.session.get_outputs()]
            
            print("âœ… YOLOv8 ONNX ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
            print(f"   ì…ë ¥: {self.session.get_inputs()[0].shape}")
            for i, output in enumerate(self.session.get_outputs()):
                print(f"   ì¶œë ¥ {i}: {output.shape}")
            
            return True
        except Exception as e:
            print(f"âŒ ONNX ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def preprocess_image(self, image):
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (YOLOv8 ONNXìš©)
        
        Args:
            image (np.array): ì›ë³¸ ì´ë¯¸ì§€ (BGR)
        
        Returns:
            tuple: (ì „ì²˜ë¦¬ëœ í…ì„œ, ì›ë³¸ í¬ê¸°)
        """
        orig_h, orig_w = image.shape[:2]
        
        # BGR -> RGB
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # 640x640ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        resized = cv2.resize(image_rgb, (640, 640))
        
        # ì •ê·œí™”: 0-255 -> 0-1
        normalized = resized.astype(np.float32) / 255.0
        
        # HWC -> CHW
        transposed = np.transpose(normalized, (2, 0, 1))
        
        # ë°°ì¹˜ ì°¨ì› ì¶”ê°€: (3, 640, 640) -> (1, 3, 640, 640)
        input_tensor = np.expand_dims(transposed, axis=0)
        
        return input_tensor, (orig_w, orig_h)
    
    def postprocess_detection(self, outputs, orig_w, orig_h):
        """
        ONNX ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬ (AI Pilotìš© ìµœì í™”)
        
        Args:
            outputs: ëª¨ë¸ ì¶œë ¥ [detection, proto_masks]
            orig_w, orig_h: ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°
        
        Returns:
            np.array: ìµœì¢… ë§ˆìŠ¤í¬ (ì›ë³¸ í¬ê¸°)
        """
        try:
            # Detection ì¶œë ¥ ì²˜ë¦¬
            detection_output = outputs[0]  # (1, 37, 8400)
            mask_protos = outputs[1] if len(outputs) > 1 else None  # (1, 32, 160, 160)
            
            if mask_protos is None:
                return np.zeros((orig_h, orig_w), dtype=np.uint8)
            
            # Detection ì¬êµ¬ì„±
            detection = detection_output[0].T  # (8400, 37)
            
            # ë°•ìŠ¤, ì‹ ë¢°ë„, ë§ˆìŠ¤í¬ ê³„ìˆ˜ ë¶„ë¦¬
            boxes = detection[:, :4]  # (8400, 4)
            class_confidences = detection[:, 4]  # (8400,)
            mask_coeffs = detection[:, 5:] if detection.shape[1] > 5 else None  # (8400, 32)
            
            if mask_coeffs is None:
                return np.zeros((orig_h, orig_w), dtype=np.uint8)
            
            # AI Pilotìš© ì ì‘í˜• ì„ê³„ê°’ (ë” ì •êµí•œ ê²€ì¶œ)
            thresholds = [0.001, 0.003, 0.005, 0.01, 0.02]
            best_results = None
            
            for threshold in thresholds:
                valid_mask = class_confidences > threshold
                valid_count = valid_mask.sum()
                
                # AI Pilotì€ ë” ë§ì€ ê°ì²´ ì²˜ë¦¬ ê°€ëŠ¥ (ì •í™•ì„± ìš°ì„ )
                if valid_count > 0 and valid_count < 80:
                    best_results = valid_mask
                    break
            
            # ìœ íš¨í•œ ê²€ì¶œì´ ì—†ìœ¼ë©´ ìƒìœ„ 5ê°œë§Œ ì‹œë„
            if best_results is None or best_results.sum() == 0:
                top_5_indices = np.argsort(class_confidences)[::-1][:5]
                best_results = np.zeros(len(class_confidences), dtype=bool)
                best_results[top_5_indices] = True
            
            detection_count = best_results.sum()
            
            if detection_count == 0:
                return np.zeros((orig_h, orig_w), dtype=np.uint8)
            
            # ìœ íš¨í•œ ê²€ì¶œ ì¶”ì¶œ
            valid_mask_coeffs = mask_coeffs[best_results]
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ìƒì„± (AI Pilotìš© - ë” ë§ì€ ê°ì²´ ì²˜ë¦¬)
            final_mask = np.zeros((orig_h, orig_w), dtype=np.uint8)
            proto_masks = mask_protos[0]  # (32, 160, 160)
            
            # AI Pilotì€ ìµœëŒ€ 10ê°œ ê°ì²´ê¹Œì§€ ì²˜ë¦¬ (ì •í™•ì„± ìš°ì„ )
            max_objects = min(len(valid_mask_coeffs), 10)
            
            for i in range(max_objects):
                # ë§ˆìŠ¤í¬ ê³„ìˆ˜ë¡œ ë§ˆìŠ¤í¬ ìƒì„±
                coeffs = valid_mask_coeffs[i]  # (32,)
                
                # í”„ë¡œí† íƒ€ì… ë§ˆìŠ¤í¬ì™€ ê³„ìˆ˜ ê³±í•˜ê¸°
                mask = np.zeros((160, 160), dtype=np.float32)
                for j in range(32):
                    mask += coeffs[j] * proto_masks[j]
                
                # Sigmoid í™œì„±í™” ë° ì´ì§„í™”
                mask = 1.0 / (1.0 + np.exp(-mask))
                mask_binary = (mask > 0.5).astype(np.uint8)
                
                # ì›ë³¸ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                mask_resized = cv2.resize(mask_binary, (orig_w, orig_h))
                
                # ìµœì¢… ë§ˆìŠ¤í¬ì— ëˆ„ì 
                final_mask = np.maximum(final_mask, mask_resized * 255)
            
            return final_mask
            
        except Exception as e:
            print(f"âŒ ONNX í›„ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return np.zeros((orig_h, orig_w), dtype=np.uint8)
    
    def create_blue_overlay(self, image, mask, alpha=0.4, blue_color=(255, 0, 0)):
        """
        ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ì— íˆ¬ëª…í•œ íŒŒë€ìƒ‰ ì˜¤ë²„ë ˆì´ ìƒì„±
        
        Args:
            image (np.array): ì›ë³¸ ì´ë¯¸ì§€
            mask (np.array): ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬
            alpha (float): íˆ¬ëª…ë„
            blue_color (tuple): BGR íŒŒë€ìƒ‰ ê°’
        
        Returns:
            np.array: ì˜¤ë²„ë ˆì´ê°€ ì ìš©ëœ ì´ë¯¸ì§€
        """
        overlay_image = image.copy()
        
        if mask is not None and np.count_nonzero(mask) > 0:
            # íŒŒë€ìƒ‰ ë ˆì´ì–´ ìƒì„±
            mask_colored = np.zeros_like(image)
            mask_colored[mask > 0] = blue_color
            
            # ì•ŒíŒŒ ë¸”ë Œë”©
            overlay_image = cv2.addWeighted(overlay_image, 1-alpha, mask_colored, alpha, 0)
        
        return overlay_image
    
    def detect_car_region(self, image):
        """ì°¨ëŸ‰ ì˜ì—­ ê°ì§€ (ì›ë³¸ê³¼ ë™ì¼)"""
        height, width = image.shape[:2]
        
        car_region = {
            'x1': int(width * 0.25),
            'y1': int(height * 0.65),
            'x2': int(width * 0.75),
            'y2': int(height * 0.95)
        }
        
        return car_region
    
    def draw_anchor_line_excluding_car(self, image, y, width, car_region, color=(0, 0, 255), thickness=2):
        """ì°¨ëŸ‰ ì˜ì—­ ì œì™¸í•˜ê³  Anchor line ê·¸ë¦¬ê¸° (ì›ë³¸ê³¼ ë™ì¼)"""
        if y >= car_region['y1'] and y <= car_region['y2']:
            cv2.line(image, (0, y), (car_region['x1'], y), color, thickness)
            cv2.line(image, (car_region['x2'], y), (width, y), color, thickness)
        else:
            cv2.line(image, (0, y), (width, y), color, thickness)
    
    def get_average_inference_time(self):
        """í‰ê·  ì¶”ë¡  ì‹œê°„ ê³„ì‚°"""
        if not self.inference_times:
            return 0.0
        return sum(self.inference_times) / len(self.inference_times)
    
    def detect_lanes_onnx(self, image):
        """
        ONNX ëª¨ë¸ë¡œ ì°¨ì„  ê°ì§€
        
        Args:
            image (np.array): ì…ë ¥ ì´ë¯¸ì§€
            
        Returns:
            tuple: (ë§ˆìŠ¤í¬, ì¶”ë¡  ì‹œê°„)
        """
        if self.session is None:
            return None, 0.0
        
        inference_start = time.time()
        
        try:
            # ì „ì²˜ë¦¬
            input_tensor, (orig_w, orig_h) = self.preprocess_image(image)
            
            # ONNX ì¶”ë¡ 
            outputs = self.session.run(self.output_names, {self.input_name: input_tensor})
            
            # í›„ì²˜ë¦¬
            mask = self.postprocess_detection(outputs, orig_w, orig_h)
            
            # ì¶”ë¡  ì‹œê°„ ê¸°ë¡
            inference_time = time.time() - inference_start
            self.inference_times.append(inference_time)
            
            # ìµœëŒ€ ê¸°ë¡ ìˆ˜ ì œí•œ
            if len(self.inference_times) > self.max_inference_history:
                self.inference_times.pop(0)
            
            return mask, inference_time
            
        except Exception as e:
            print(f"âŒ ONNX ì°¨ì„  ê°ì§€ ì˜¤ë¥˜: {e}")
            return None, 0.0

class DSSYOLOONNXController:
    def __init__(self, model_path):
        """
        DSS + YOLOv8 ONNX AI Pilot í†µí•© ì»¨íŠ¸ë¡¤ëŸ¬
        
        Args:
            model_path (str): YOLOv8 ONNX ëª¨ë¸ ê²½ë¡œ
        """
        self.running = True
        self.rgb_image = None
        self.dss_instance = None
        self.last_key_pressed = None
        
        self.drive_state = {
            'throttle': 0.0,
            'steer': 0.0,
            'brake': 0.0
        }
        
        # YOLOv8 ONNX ì°¨ì„  ê°ì§€ê¸° ì´ˆê¸°í™”
        self.lane_detector = YOLOv8ONNXLaneDetector(model_path)
        
        # Anchor line ì„¤ì • (í”½ì…€ ê°’ìœ¼ë¡œ ê´€ë¦¬, ìœ„ì—ì„œ 0 ê¸°ì¤€)
        self.anchor_lines = []
        self.show_anchor_lines = True
        self.selected_line_index = 0
        self.edit_mode = False
        self.image_height = 480
        self.initialize_default_anchor_lines()
        
        # í”„ë¡œê·¸ë¨ ì‹œì‘ì‹œ ìë™ìœ¼ë¡œ JSON íŒŒì¼ ë¡œë“œ ì‹œë„
        self.load_anchor_config()
        
        # ì„±ëŠ¥ ì¸¡ì • ë³€ìˆ˜
        self.fps_counter = 0
        self.fps_start_time = time.time()
        self.fps = 0
        self.total_inference_time = 0.0
        self.frame_count = 0
        
        print("ğŸš— DSS + YOLOv8 ONNX AI Pilot ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!")
    
    def initialize_default_anchor_lines(self):
        """ê¸°ë³¸ Anchor lines ì´ˆê¸°í™”"""
        default_positions = [200, 250, 300, 350, 400, 450]
        self.anchor_lines = [pos for pos in default_positions]
        print(f"ğŸ“ ê¸°ë³¸ Anchor lines ì´ˆê¸°í™”: {len(self.anchor_lines)}ê°œ (í”½ì…€ ê°’)")
        self.print_anchor_positions()
    
    def update_image_height(self, height):
        """ì´ë¯¸ì§€ ë†’ì´ ì—…ë°ì´íŠ¸"""
        if self.image_height != height:
            self.image_height = height
            print(f"ğŸ“ ì´ë¯¸ì§€ ë†’ì´ ì—…ë°ì´íŠ¸: {height}px")
    
    def get_anchor_y_positions(self, image_height):
        """ìœ íš¨í•œ Anchor Y ìœ„ì¹˜ ë°˜í™˜"""
        self.update_image_height(image_height)
        valid_positions = [y for y in self.anchor_lines if 0 <= y < image_height]
        return valid_positions
    
    def add_anchor_line(self, pixel_position=None):
        """Anchor line ì¶”ê°€"""
        if pixel_position is None:
            if self.anchor_lines:
                pixel_position = min(self.image_height - 20, max(self.anchor_lines) + 50)
            else:
                pixel_position = 300
        
        pixel_position = max(10, min(self.image_height - 10, pixel_position))
        
        self.anchor_lines.append(pixel_position)
        self.anchor_lines.sort()
        print(f"â• Anchor line ì¶”ê°€: Y={pixel_position}px")
        self.print_anchor_positions()
    
    def remove_anchor_line(self, index=None):
        """Anchor line ì œê±°"""
        if not self.anchor_lines:
            return
        
        if index is None:
            index = self.selected_line_index
        
        if 0 <= index < len(self.anchor_lines):
            removed_pos = self.anchor_lines.pop(index)
            print(f"â– Anchor line ì œê±°: Y={removed_pos}px")
            
            if self.selected_line_index >= len(self.anchor_lines):
                self.selected_line_index = max(0, len(self.anchor_lines) - 1)
            
            self.print_anchor_positions()
    
    def move_selected_line(self, direction, step=5):
        """ì„ íƒëœ ë¼ì¸ ì´ë™"""
        if not self.anchor_lines or not (0 <= self.selected_line_index < len(self.anchor_lines)):
            return
        
        current_pos = self.anchor_lines[self.selected_line_index]
        
        if direction == 'up':
            new_pos = max(10, current_pos - step)
        else:
            new_pos = min(self.image_height - 10, current_pos + step)
        
        self.anchor_lines[self.selected_line_index] = new_pos
        self.anchor_lines.sort()
        
        self.selected_line_index = self.anchor_lines.index(new_pos)
        
        print(f"ğŸ“ Line {self.selected_line_index + 1} ì´ë™: Y={new_pos}px")
    
    def select_next_line(self):
        """ë‹¤ìŒ ë¼ì¸ ì„ íƒ"""
        if self.anchor_lines:
            self.selected_line_index = (self.selected_line_index + 1) % len(self.anchor_lines)
            selected_y = self.anchor_lines[self.selected_line_index]
            print(f"ğŸ¯ Line {self.selected_line_index + 1} ì„ íƒë¨ (Y={selected_y}px)")
    
    def select_prev_line(self):
        """ì´ì „ ë¼ì¸ ì„ íƒ"""
        if self.anchor_lines:
            self.selected_line_index = (self.selected_line_index - 1) % len(self.anchor_lines)
            selected_y = self.anchor_lines[self.selected_line_index]
            print(f"ğŸ¯ Line {self.selected_line_index + 1} ì„ íƒë¨ (Y={selected_y}px)")
    
    def toggle_edit_mode(self):
        """í¸ì§‘ ëª¨ë“œ í† ê¸€"""
        self.edit_mode = not self.edit_mode
        mode_text = "í¸ì§‘ ëª¨ë“œ" if self.edit_mode else "ì¼ë°˜ ëª¨ë“œ"
        print(f"ğŸ”§ {mode_text} ì „í™˜")
        if self.edit_mode:
            self.print_anchor_positions()
    
    def print_anchor_status(self):
        """Anchor ìƒíƒœ ì¶œë ¥"""
        print(f"\nğŸ“ Anchor Lines ìƒíƒœ (ì´ë¯¸ì§€ ë†’ì´: {self.image_height}px):")
        for i, pos in enumerate(self.anchor_lines):
            marker = "ğŸ‘‰" if i == self.selected_line_index else "  "
            print(f"{marker} Line {i+1}: Y={pos}px")
        print(f"í¸ì§‘ ëª¨ë“œ: {'ON' if self.edit_mode else 'OFF'}")
        print()
    
    def print_anchor_positions(self):
        """Anchor ìœ„ì¹˜ ì¶œë ¥"""
        if self.anchor_lines:
            positions_str = ", ".join([f"Y{pos}" for pos in self.anchor_lines])
            print(f"ğŸ“ Anchor ìœ„ì¹˜: {positions_str}")
    
    def save_anchor_config(self, filename="anchor_config.json"):
        """Anchor ì„¤ì • ì €ì¥"""
        config = {
            'anchor_lines': self.anchor_lines,
            'show_anchor_lines': self.show_anchor_lines,
            'image_height': self.image_height,
            'format': 'pixels_from_top',
            'model_type': 'onnx'
        }
        try:
            with open(filename, 'w') as f:
                json.dump(config, f, indent=2)
            print(f"ğŸ’¾ Anchor ì„¤ì • ì €ì¥: {filename}")
            self.print_anchor_positions()
        except Exception as e:
            print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def load_anchor_config(self, filename="anchor_config.json"):
        """Anchor ì„¤ì • ë¡œë“œ"""
        try:
            with open(filename, 'r') as f:
                config = json.load(f)
            
            if config.get('format') == 'pixels_from_top':
                self.anchor_lines = config.get('anchor_lines', [])
            else:
                old_ratios = config.get('anchor_lines', [])
                self.anchor_lines = [int(ratio * self.image_height) for ratio in old_ratios]
                print("âš¡ ê¸°ì¡´ ë¹„ìœ¨ ì„¤ì •ì„ í”½ì…€ ê°’ìœ¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤.")
            
            self.show_anchor_lines = config.get('show_anchor_lines', True)
            self.selected_line_index = 0
            print(f"ğŸ“‚ Anchor ì„¤ì • ë¡œë“œ: {filename}")
            self.print_anchor_positions()
            
        except FileNotFoundError:
            print(f"âš ï¸  {filename} íŒŒì¼ì´ ì—†ì–´ì„œ ê¸°ë³¸ ì„¤ì •ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            self.initialize_default_anchor_lines()
        except Exception as e:
            print(f"âŒ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.initialize_default_anchor_lines()
    
    def find_available_onnx_models(self, base_path):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ONNX ëª¨ë¸ ì°¾ê¸°"""
        training_dir = os.path.join(base_path, "DSS_AI_training")
        available_models = []
        
        if os.path.exists(training_dir):
            for experiment in os.listdir(training_dir):
                onnx_model_path = os.path.join(training_dir, experiment, "weights", "onnx_models", "best.onnx")
                if os.path.exists(onnx_model_path):
                    available_models.append({
                        'name': f"{experiment}_onnx",
                        'path': onnx_model_path,
                        'size': os.path.getsize(onnx_model_path) / (1024*1024)
                    })
        
        return available_models
    
    def switch_onnx_model(self, key):
        """ONNX ëª¨ë¸ ì „í™˜"""
        base_path = r"C:\Project\DSS\AI_Academy\yolov8"
        models = self.find_available_onnx_models(base_path)
        
        if key >= ord('1') and key <= ord('9'):
            model_index = key - ord('1')
            if model_index < len(models):
                new_model_path = models[model_index]['path']
                print(f"ğŸ”„ ONNX ëª¨ë¸ ì „í™˜ ì¤‘: {models[model_index]['name']}")
                
                old_detector = self.lane_detector
                self.lane_detector = YOLOv8ONNXLaneDetector(new_model_path)
                
                if self.lane_detector.session is not None:
                    print(f"âœ… ONNX ëª¨ë¸ ì „í™˜ ì™„ë£Œ: {models[model_index]['name']}")
                    del old_detector
                else:
                    print(f"âŒ ONNX ëª¨ë¸ ì „í™˜ ì‹¤íŒ¨, ê¸°ì¡´ ëª¨ë¸ ìœ ì§€")
                    self.lane_detector = old_detector
    
    def normalize_angle(self, angle):
        """ê°ë„ ì •ê·œí™” (â€“Ï€ ~ +Ï€ ë²”ìœ„)"""
        return (angle + np.pi) % (2 * np.pi) - np.pi
        
    def compute_stanley_control(self, center_points, vehicle_position_x, heading, k=0.5):
        """Stanley Control ì•Œê³ ë¦¬ì¦˜ (ì›ë³¸ê³¼ ë™ì¼)"""
        if len(center_points) < 3:
            return 0.0  # insufficient anchor points

        target_point = center_points[2]  # (x, y)

        dx = target_point[0] - vehicle_position_x  # ì¢Œìš° ì˜¤ì°¨ (ê°€ë¡œ ë°©í–¥)
        dy = self.image_height - target_point[1]   # ì „ë°© ê±°ë¦¬ (ì„¸ë¡œ ë°©í–¥, ìœ„->ì•„ë˜ flip ë³´ì •)

        print(f"[Stanley Debug] vehicle_x: {vehicle_position_x}, target_x: {target_point[0]}, dx: {dx}")
        print(f"[Stanley Debug] vehicle_x: {vehicle_position_x}, target_point: {target_point}, dx: {dx}")

        path_angle = np.arctan2(dx, 3*dy)  # â¬…ï¸ ì´ì œ dyê°€ ì–‘ìˆ˜
        heading_error = path_angle - heading

        heading_error = self.normalize_angle(path_angle - heading)

        cross_track_error = dx / max(1e-3, np.hypot(dx, dy))
        steer = heading_error + np.arctan2(k * cross_track_error, 200.0)
        steer_deg = np.degrees(steer)

         # ë””ë²„ê¹… ì¶œë ¥ ì¶”ê°€
        print(f"[Stanley Debug] dx: {dx:.2f}, dy: {dy:.2f}, path_angle(deg): {np.degrees(path_angle):.2f}, heading(deg): {np.degrees(heading):.2f}, heading_error(deg): {np.degrees(heading_error):.2f}")
        print(f"[Stanley] dx: {dx:.2f}, dy: {dy:.2f}, cross_track_error: {cross_track_error:.4f}, heading_error: {heading_error:.4f}, steer(deg): {steer_deg:.4f}")

        steer = np.clip(steer, -np.radians(30), np.radians(30))  # ì œí•œ ê°ë„
        return steer

    def draw_anchor_lines_and_center(self, image, mask):
        """Anchor lines ê·¸ë¦¬ê¸° ë° ì¤‘ì‹¬ì  ê³„ì‚°"""
        if mask is None or mask.sum() == 0:
            return image, []

        result_image = image.copy()
        height, width = image.shape[:2]

        self.update_image_height(height)
        car_region = self.lane_detector.detect_car_region(image)
        y_positions = self.get_anchor_y_positions(height)

        center_points = []

        for i, y in enumerate(y_positions):
            if y < 0 or y >= height:
                continue

            line_mask = mask[y, :]
            lane_pixels = np.where(line_mask > 0)[0]

            if len(lane_pixels) > 0:
                left_most = lane_pixels[0]
                right_most = lane_pixels[-1]
                center_x = (left_most + right_most) // 2
                center_points.append((center_x, y))

                line_color = (0, 255, 255) if self.edit_mode and i == self.selected_line_index else (0, 0, 255)
                line_thickness = 4 if self.edit_mode and i == self.selected_line_index else 2
                self.lane_detector.draw_anchor_line_excluding_car(result_image, y, width, car_region, line_color, line_thickness)

                point_color = (255, 255, 0) if self.edit_mode and i == self.selected_line_index else (0, 255, 0)
                cv2.circle(result_image, (center_x, y), 4, point_color, -1)

                if self.edit_mode:
                    cv2.putText(result_image, f"L{i+1}:Y{y}", (center_x + 10, y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)

        if len(center_points) >= 2:
            for i in range(len(center_points) - 1):
                cv2.line(result_image, center_points[i], center_points[i + 1], (0, 255, 0), 3)

        return result_image, center_points
    
    def handle_key_control(self, key):
        """í‚¤ë³´ë“œ ì…ë ¥ ì²˜ë¦¬"""
        step = 0.05
        
        if key >= ord('1') and key <= ord('9'):
            self.switch_onnx_model(key)
            return
        
        if self.edit_mode:
            if key == ord('w') or key == 72:
                self.move_selected_line('up')
                return
            elif key == ord('s') or key == 80:
                self.move_selected_line('down')
                return
            elif key == ord('d') or key == 77:
                self.select_next_line()
                return
            elif key == ord('a') or key == 75:
                self.select_prev_line()
                return
            elif key == ord('q'):
                self.add_anchor_line()
                return
            elif key == ord('e'):
                self.remove_anchor_line()
                return
            elif key == ord('p'):
                self.print_anchor_status()
                return
        
        if key == ord('=') or key == ord('+'):
            self.add_anchor_line()
            return
        elif key == ord('-') or key == ord('_'):
            self.remove_anchor_line()
            return
        elif key == ord('t'):
            self.show_anchor_lines = not self.show_anchor_lines
            status = "ON" if self.show_anchor_lines else "OFF"
            print(f"[ANCHOR] Anchor lines: {status}")
            return
        elif key == ord('g'):
            self.toggle_edit_mode()
            return
        elif key == ord('h'):
            self.print_help()
            return
        elif key == ord('m'):
            self.save_anchor_config()
            return
        elif key == ord('n'):
            self.load_anchor_config()
            return
        
        if not self.edit_mode:
            if key == ord('w'):
                self.drive_state['throttle'] = min(1.0, self.drive_state['throttle'] + step)
            elif key == ord('s'):
                self.drive_state['throttle'] = max(0.0, self.drive_state['throttle'] - step)
            elif key == ord('j'):
                self.drive_state['steer'] = max(-1.0, self.drive_state['steer'] - step)
            elif key == ord('l'):
                self.drive_state['steer'] = min(1.0, self.drive_state['steer'] + step)
            elif key == ord('k'):
                self.drive_state['steer'] = 0.0
            elif key == ord('x'):
                self.drive_state['brake'] = min(1.0, self.drive_state['brake'] + step)
            elif key == ord('z'):
                self.drive_state['brake'] = max(0.0, self.drive_state['brake'] - step)
            elif key == ord('r'):
                self.drive_state = {'throttle': 0.0, 'steer': 0.0, 'brake': 0.0}
            
            print(f"[CONTROL] T:{self.drive_state['throttle']:.2f} S:{self.drive_state['steer']:.2f} B:{self.drive_state['brake']:.2f}")
    
    def print_help(self):
        """ë„ì›€ë§ ì¶œë ¥"""
        print("\n" + "="*60)
        print("ğŸ® ONNX AI Pilot í‚¤ë³´ë“œ ì¡°ì‘ë²•")
        print("="*60)
        print("ã€ì°¨ëŸ‰ ì œì–´ã€‘")
        print("  W/S: ê°€ì†/ê°ì†")
        print("  J/L: ì¢Œ/ìš° ì¡°í–¥")
        print("  K: ì¡°í–¥ ì¤‘ì•™")
        print("  X/Z: ë¸Œë ˆì´í¬")
        print("  R: ëª¨ë“  ì œì–´ ë¦¬ì…‹")
        print()
        print("ã€ONNX ëª¨ë¸ ê´€ë¦¬ã€‘")
        print("  1-9: ONNX ëª¨ë¸ ì „í™˜")
        print()
        print("ã€Anchor Line ì œì–´ã€‘")
        print("  T: Anchor line í‘œì‹œ í† ê¸€")
        print("  G: í¸ì§‘ ëª¨ë“œ í† ê¸€")
        print("  +: ë¼ì¸ ì¶”ê°€")
        print("  -: ë¼ì¸ ì œê±°")
        print("  M: ì„¤ì • ì €ì¥")
        print("  N: ì„¤ì • ë¡œë“œ")
        print("  H: ë„ì›€ë§")
        print()
        print("ã€í¸ì§‘ ëª¨ë“œì—ì„œã€‘")
        print("  W/S ë˜ëŠ” â†‘/â†“: ì„ íƒëœ ë¼ì¸ ìœ„/ì•„ë˜ ì´ë™ (5px ë‹¨ìœ„)")
        print("  A/D ë˜ëŠ” â†/â†’: ì´ì „/ë‹¤ìŒ ë¼ì¸ ì„ íƒ")
        print("  Q: ë¼ì¸ ì¶”ê°€")
        print("  E: ì„ íƒëœ ë¼ì¸ ì œê±°")
        print("  P: í˜„ì¬ ìƒíƒœ ì¶œë ¥")
        print("="*60)
        print()
    
    def calculate_fps(self):
        """FPS ê³„ì‚°"""
        self.fps_counter += 1
        current_time = time.time()
        if current_time - self.fps_start_time >= 1.0:
            self.fps = self.fps_counter
            self.fps_counter = 0
            self.fps_start_time = current_time
    
    def add_overlay_info(self, image, inference_time=0.0):
        """ì´ë¯¸ì§€ì— ì •ë³´ ì˜¤ë²„ë ˆì´ ì¶”ê°€"""
        # FPS í‘œì‹œ
        cv2.putText(image, f'FPS: {self.fps}', (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        
        # ONNX ì¶”ë¡  ì‹œê°„ í‘œì‹œ
        cv2.putText(image, f'ONNX Inf: {inference_time*1000:.1f}ms', (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # í‰ê·  ì¶”ë¡  ì‹œê°„ í‘œì‹œ
        avg_inference = self.lane_detector.get_average_inference_time()
        cv2.putText(image, f'Avg: {avg_inference*1000:.1f}ms', (10, 110), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
        
        # ì°¨ëŸ‰ ìƒíƒœ í‘œì‹œ
        info_text = f'T:{self.drive_state["throttle"]:.2f} S:{self.drive_state["steer"]:.2f} B:{self.drive_state["brake"]:.2f}'
        cv2.putText(image, info_text, (10, 150), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # Anchor line ì •ë³´ í‘œì‹œ
        anchor_info = f'Lines: {len(self.anchor_lines)} | Mode: {"EDIT" if self.edit_mode else "DRIVE"}'
        if self.edit_mode and self.anchor_lines:
            anchor_info += f' | Selected: {self.selected_line_index + 1}'
        cv2.putText(image, anchor_info, (10, 190), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
        
        # ONNX AI Pilot í‘œì‹œ
        cv2.putText(image, 'ONNX AI PILOT', (image.shape[1] - 250, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 255), 2)
        
        # ì¡°ì‘ë²• í‘œì‹œ
        if self.edit_mode:
            cv2.putText(image, 'EDIT: W/S:Move A/D:Select Q:Add E:Del P:Status G:Exit H:Help', 
                       (10, image.shape[0] - 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 1)
            cv2.putText(image, 'ESC:Exit', 
                       (10, image.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
        else:
            cv2.putText(image, 'W/S:Throttle J/L:Steer K:Center X/Z:Brake R:Reset', 
                       (10, image.shape[0] - 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
            cv2.putText(image, '1-9:ONNX Model T:Toggle G:Edit +/-:Lines M/N:Save/Load H:Help ESC:Exit', 
                       (10, image.shape[0] - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
        
        return image
    
    def on_camera_data(self, image: dss_pb2.DSSImage):
        """ì¹´ë©”ë¼ ë°ì´í„° ì½œë°± (ONNX AI Pilot)"""
        if not self.running:
            return
        
        start_time = time.time()
        
        try:
            jpg_data = np.frombuffer(image.data, dtype=np.uint8)
            self.rgb_image = cv2.imdecode(jpg_data, cv2.IMREAD_COLOR)

            if self.rgb_image is None:
                return

            lane_detected_image = self.rgb_image
            inference_time = 0.0

            if self.lane_detector.session is not None:
                # ONNX ì°¨ì„  ê°ì§€
                combined_mask, inference_time = self.lane_detector.detect_lanes_onnx(self.rgb_image)
                
                # ì„±ëŠ¥ í†µê³„ ì—…ë°ì´íŠ¸
                self.total_inference_time += inference_time
                self.frame_count += 1
                
                if combined_mask is not None and combined_mask.sum() > 0:
                    overlay_image = self.lane_detector.create_blue_overlay(self.rgb_image, combined_mask, alpha=0.1)

                    if self.show_anchor_lines:
                        lane_detected_image, center_points = self.draw_anchor_lines_and_center(overlay_image, combined_mask)

                        # Stanley Control ì ìš©
                        if len(center_points) >= 3:
                            vehicle_x = self.rgb_image.shape[1] // 2
                            heading = 0.0  # ì •ë©´ ê¸°ì¤€
                            steer_rad = self.compute_stanley_control(center_points, vehicle_x, heading)
                            steer_deg = np.degrees(steer_rad)
                            steer_cmd = steer_deg * 0.17  # ì°¨ëŸ‰ìš© ìŠ¤ì¼€ì¼ ì¡°í–¥ê°’
                            self.drive_state['steer'] = steer_cmd

                            # ë””ë²„ê¹… ì¶œë ¥
                            print(f"[ONNX Stanley] steer_deg: {steer_deg:.2f}, steer_cmd: {steer_cmd:.2f}")
                        else:
                            lane_detected_image = overlay_image

            final_image = self.add_overlay_info(lane_detected_image, inference_time)
            self.calculate_fps()

            cv2.imshow('DSS Camera + ONNX AI Pilot', final_image)

            key = cv2.waitKey(1) & 0xFF
            if key == 27:
                self.running = False
                cv2.destroyAllWindows()
                
                # ìµœì¢… ì„±ëŠ¥ í†µê³„ ì¶œë ¥
                if self.frame_count > 0:
                    avg_inference = self.total_inference_time / self.frame_count
                    print(f"\nğŸ“Š ONNX AI Pilot ìµœì¢… ì„±ëŠ¥ í†µê³„:")
                    print(f"   ì´ í”„ë ˆì„: {self.frame_count}")
                    print(f"   í‰ê·  ì¶”ë¡  ì‹œê°„: {avg_inference*1000:.2f}ms")
                    print(f"   ìµœëŒ€ FPS: {1.0/avg_inference:.1f}")
                
            elif key != 255:
                self.last_key_pressed = chr(key) if 32 <= key <= 126 else str(key)
                self.handle_key_control(key)

        except Exception as e:
            print(f"âŒ ONNX ì¹´ë©”ë¼ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        finally:
            end_time = time.time()
            duration_ms = (end_time - start_time) * 1000
            print(f"[â±ï¸ ONNX ì²˜ë¦¬ ì‹œê°„] on_camera_data duration: {duration_ms:.2f} ms")
    
    def on_lidar_data(self, lidar_data):
        """ë¼ì´ë‹¤ ë°ì´í„° ì½œë°±"""
        if not self.running:
            return
    
    def on_imu_data(self, imu):
        """IMU ë°ì´í„° ì½œë°±"""
        if not self.running:
            return
    
    def on_gps_data(self, gps):
        """GPS ë°ì´í„° ì½œë°±"""
        if not self.running:
            return
    
    def on_odom_data(self, odom):
        """ì˜¤ë„ë©”íŠ¸ë¦¬ ë°ì´í„° ì½œë°±"""
        if not self.running:
            return
    
    def on_ground_truth_data(self, gt_data):
        """ê·¸ë¼ìš´ë“œ íŠ¸ë£¨ìŠ¤ ë°ì´í„° ì½œë°±"""
        if not self.running:
            return
    
    def on_sim_started(self):
        """ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ì½œë°±"""
        print("ğŸŸ¢ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘!")
    
    def on_sim_ended(self):
        """ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ ì½œë°±"""
        print("ğŸ”´ ì‹œë®¬ë ˆì´ì…˜ ì¢…ë£Œ!")
        self.running = False
    
    def on_sim_aborted(self):
        """ì‹œë®¬ë ˆì´ì…˜ ì¤‘ë‹¨ ì½œë°±"""
        print("âš ï¸ ì‹œë®¬ë ˆì´ì…˜ ì¤‘ë‹¨!")
        self.running = False
    
    def on_sim_error(self):
        """ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜ ì½œë°±"""
        print("âŒ ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜!")
        self.running = False
    
    def update_vehicle_control(self):
        """ì°¨ëŸ‰ ì œì–´ ì—…ë°ì´íŠ¸"""
        if not self.running or not self.dss_instance:
            return
        
        control = DSSSDKCarControl(
            throttle=self.drive_state['throttle'],
            steer=self.drive_state['steer'],
            brake=self.drive_state['brake'],
            park_brake=False,
            target_gear=1
        )
        
        try:
            with SuppressOutput():
                self.dss_instance.set_car_control(control)
        except Exception as e:
            print(f"âŒ ì°¨ëŸ‰ ì œì–´ ì˜¤ë¥˜: {e}")
    
    def signal_handler(self, sig, frame):
        """ì‹œê·¸ë„ í•¸ë“¤ëŸ¬"""
        print("\nğŸ›‘ ONNX AI Pilot ì¢…ë£Œ ì¤‘...")
        self.running = False
        try:
            loop = asyncio.get_event_loop()
            loop.call_soon_threadsafe(loop.stop)
        except RuntimeError:
            pass
    
    def run(self, server_ip="127.0.0.1"):
        """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
        
        os.environ['PYTHONPATH'] = ''
        
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            print(f"ğŸ”— DSS ì„œë²„ ì—°ê²° ì¤‘: {server_ip}")
            
            with SuppressOutput():
                dss = IDSSSDK.create(
                    loop=loop,
                    nats_address=f'nats://{server_ip}:4222'
                )
                self.dss_instance = dss
                
                init_params = DSSSDKInitParams(
                    server=server_ip,
                    heartbeat_port=8886,
                    nats_port=4222
                )
                
                dss.initialize(init_params)
                dss.register_sensor_callback('camera', self.on_camera_data)
                dss.register_simulation_callback('started', self.on_sim_started)
                dss.register_simulation_callback('ended', self.on_sim_ended)
                dss.register_simulation_callback('aborted', self.on_sim_aborted)
                dss.register_simulation_callback('error', self.on_sim_error)
                
                dss.start()
            
            print("âœ… DSS ì—°ê²° ì™„ë£Œ!")
            print("ğŸ® ONNX AI Pilot í‚¤ë³´ë“œ ì¡°ì‘ë²•:")
            print("   W/S: ê°€ì†/ê°ì†")
            print("   J/L: ì¢ŒíšŒì „/ìš°íšŒì „") 
            print("   K: ì¡°í–¥ ì¤‘ì•™")
            print("   X/Z: ë¸Œë ˆì´í¬")
            print("   R: ë¦¬ì…‹")
            print("   1-9: ONNX ëª¨ë¸ ì „í™˜")
            print("   T: Anchor line í‘œì‹œ í† ê¸€")
            print("   G: í¸ì§‘ ëª¨ë“œ ì „í™˜")
            print("   +/-: Anchor line ì¶”ê°€/ì œê±°")
            print("   M/N: ì„¤ì • ì €ì¥/ë¡œë“œ")
            print("   H: ë„ì›€ë§")
            print("   ESC: ì¢…ë£Œ")
            print("=" * 50)
            
            while self.running:
                self.update_vehicle_control()
                time.sleep(0.1)
                
        except KeyboardInterrupt:
            print("\nâŒ¨ï¸  í‚¤ë³´ë“œ ì¸í„°ëŸ½íŠ¸ë¡œ ì¢…ë£Œ")
            self.running = False
        except Exception as e:
            print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
            self.running = False
        finally:
            if self.dss_instance:
                try:
                    with SuppressOutput():
                        self.dss_instance.cleanup()
                except Exception:
                    pass
            cv2.destroyAllWindows()
            print("ğŸ ONNX AI Pilot ì¢…ë£Œ ì™„ë£Œ")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸš— DSS + YOLOv8 ONNX AI Pilot ììœ¨ì£¼í–‰ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    BASE_PATH = r"C:\Project\DSS\AI_Academy\yolov8"
    EXPERIMENT_NAME = "DSS_experiment_1"
    MODEL_PATH = os.path.join(BASE_PATH, "DSS_AI_training", EXPERIMENT_NAME, "weights", "onnx_models", "best.onnx")
    
    print(f"ğŸ“‚ ONNX ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    
    def find_onnx_models(base_path):
        """ONNX ëª¨ë¸ ì°¾ê¸°"""
        training_dir = os.path.join(base_path, "DSS_AI_training")
        available_models = []
        if os.path.exists(training_dir):
            for experiment in os.listdir(training_dir):
                onnx_model_path = os.path.join(training_dir, experiment, "weights", "onnx_models", "best.onnx")
                if os.path.exists(onnx_model_path):
                    available_models.append({
                        'name': f"{experiment}_onnx",
                        'path': onnx_model_path,
                        'size': os.path.getsize(onnx_model_path) / (1024*1024)
                    })
        return available_models
    
    available_models = find_onnx_models(BASE_PATH)
    
    if available_models:
        print(f"\nğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ONNX ëª¨ë¸ë“¤:")
        for i, model in enumerate(available_models, 1):
            print(f"   {i}: {model['name']} ({model['size']:.1f}MB)")
        print("   ì‹¤í–‰ ì¤‘ 1-9 í‚¤ë¡œ ONNX ëª¨ë¸ ì „í™˜ ê°€ëŠ¥")
    
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ ONNX ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
        print("ë¨¼ì € YOLOv8 ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”.")
        return
    
    server_ip = "127.0.0.1"
    
    try:
        controller = DSSYOLOONNXController(MODEL_PATH)
        controller.run(server_ip)
        
    except Exception as e:
        print(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    finally:
        print("ğŸ‘‹ ONNX AI Pilot ì‹œìŠ¤í…œ ì¢…ë£Œ")

if __name__ == "__main__":
    main()