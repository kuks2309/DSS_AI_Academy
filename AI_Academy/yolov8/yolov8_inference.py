import os
import cv2
import numpy as np
from ultralytics import YOLO
import matplotlib.pyplot as plt
from pathlib import Path
import glob

class YOLOv8SegmentationInference:
    def __init__(self, model_path, test_folder_path):
        """
        YOLOv8 ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  í´ë˜ìŠ¤
        
        Args:
            model_path (str): í•™ìŠµëœ ëª¨ë¸ ê²½ë¡œ (best.pt)
            test_folder_path (str): í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        """
        self.model_path = model_path
        self.test_folder_path = test_folder_path
        self.model = None
        self.load_model()
    
    def load_model(self):
        """í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
        if not os.path.exists(self.model_path):
            raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.model_path}")
        
        print(f"ğŸ“¥ ëª¨ë¸ ë¡œë“œ ì¤‘: {self.model_path}")
        self.model = YOLO(self.model_path)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
    
    def get_test_images(self):
        """í…ŒìŠ¤íŠ¸ í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°"""
        image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
        image_files = []
        
        for ext in image_extensions:
            pattern = os.path.join(self.test_folder_path, ext)
            image_files.extend(glob.glob(pattern))
            # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´
            pattern_upper = os.path.join(self.test_folder_path, ext.upper())
            image_files.extend(glob.glob(pattern_upper))
        
        image_files = list(set(image_files))  # ì¤‘ë³µ ì œê±°
        print(f"ğŸ“ ë°œê²¬ëœ ì´ë¯¸ì§€: {len(image_files)}ê°œ")
        
        return sorted(image_files)
    
    def create_blue_overlay(self, image, mask, alpha=0.4, blue_color=(255, 0, 0)):
        """
        ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ì— íˆ¬ëª…í•œ íŒŒë€ìƒ‰ ì˜¤ë²„ë ˆì´ ìƒì„±
        
        Args:
            image (np.array): ì›ë³¸ ì´ë¯¸ì§€
            mask (np.array): ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬
            alpha (float): íˆ¬ëª…ë„ (0.0-1.0)
            blue_color (tuple): BGR íŒŒë€ìƒ‰ ê°’
        
        Returns:
            np.array: ì˜¤ë²„ë ˆì´ê°€ ì ìš©ëœ ì´ë¯¸ì§€
        """
        # ì´ë¯¸ì§€ ë³µì‚¬
        overlay_image = image.copy()
        
        # ë§ˆìŠ¤í¬ê°€ ìˆëŠ” ë¶€ë¶„ì— íŒŒë€ìƒ‰ ì ìš©
        if mask is not None and mask.sum() > 0:
            # ë§ˆìŠ¤í¬ë¥¼ 3ì±„ë„ë¡œ í™•ì¥
            if len(mask.shape) == 2:
                mask_3d = np.stack([mask] * 3, axis=-1)
            else:
                mask_3d = mask
            
            # íŒŒë€ìƒ‰ ë ˆì´ì–´ ìƒì„±
            blue_layer = np.zeros_like(image)
            blue_layer[:, :] = blue_color  # BGR ìˆœì„œë¡œ íŒŒë€ìƒ‰
            
            # ë§ˆìŠ¤í¬ ì˜ì—­ì—ë§Œ íŒŒë€ìƒ‰ ì ìš© (ì•ŒíŒŒ ë¸”ë Œë”©)
            mask_bool = mask_3d > 0
            overlay_image[mask_bool] = (
                alpha * blue_layer[mask_bool] + 
                (1 - alpha) * overlay_image[mask_bool]
            ).astype(np.uint8)
        
        return overlay_image
    
    def process_single_image(self, image_path, save_result=True, show_result=True, use_cv2=True):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
        
        Args:
            image_path (str): ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            save_result (bool): ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            show_result (bool): ê²°ê³¼ í™”ë©´ í‘œì‹œ ì—¬ë¶€
            use_cv2 (bool): OpenCV í‘œì‹œ ì‚¬ìš© ì—¬ë¶€ (True=ë¹ ë¦„, False=matplotlib)
        """
        print(f"\nğŸ” ì²˜ë¦¬ ì¤‘: {os.path.basename(image_path)}")
        
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(image_path)
        if image is None:
            print(f"âŒ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            return None, False
        
        # ëª¨ë¸ ì¶”ë¡ 
        results = self.model(image_path, conf=0.25, verbose=False)
        
        if not results or not results[0].masks:
            print("âš ï¸  ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            overlay_image = image
        else:
            # ì²« ë²ˆì§¸ ê²°ê³¼ì—ì„œ ë§ˆìŠ¤í¬ ì¶”ì¶œ
            masks = results[0].masks.data.cpu().numpy()
            
            # ëª¨ë“  ë§ˆìŠ¤í¬ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹˜ê¸°
            combined_mask = np.zeros((image.shape[0], image.shape[1]), dtype=np.uint8)
            
            for mask in masks:
                # ë§ˆìŠ¤í¬ë¥¼ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                mask_resized = cv2.resize(mask, (image.shape[1], image.shape[0]))
                mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255
                combined_mask = cv2.bitwise_or(combined_mask, mask_binary)
            
            # íŒŒë€ìƒ‰ ì˜¤ë²„ë ˆì´ ì ìš©
            overlay_image = self.create_blue_overlay(
                image, 
                combined_mask, 
                alpha=0.4, 
                blue_color=(255, 0, 0)  # BGR í˜•ì‹ì˜ íŒŒë€ìƒ‰
            )
            
            print(f"âœ… ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ: {len(masks)}ê°œ ë§ˆìŠ¤í¬ ê°ì§€")
        
        # ê²°ê³¼ ì €ì¥
        if save_result:
            output_dir = os.path.join(os.path.dirname(image_path), '..', 'results')
            os.makedirs(output_dir, exist_ok=True)
            
            filename = os.path.basename(image_path)
            name, ext = os.path.splitext(filename)
            output_path = os.path.join(output_dir, f"{name}_segmented{ext}")
            
            cv2.imwrite(output_path, overlay_image)
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")
        
        # ê²°ê³¼ í™”ë©´ í‘œì‹œ
        should_exit = False
        if show_result:
            if use_cv2:
                should_exit = self.display_result_cv2(image, overlay_image, os.path.basename(image_path))
            else:
                self.display_result(image, overlay_image, os.path.basename(image_path))
        
        return overlay_image, should_exit
    
    def display_result(self, original, result, title):
        """
        ì›ë³¸ê³¼ ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ í‘œì‹œ (í‚¤ ì…ë ¥ ëŒ€ê¸°)
        
        Args:
            original (np.array): ì›ë³¸ ì´ë¯¸ì§€
            result (np.array): ì²˜ë¦¬ëœ ì´ë¯¸ì§€
            title (str): ì œëª©
        """
        # BGR to RGB ë³€í™˜ (matplotlibìš©)
        original_rgb = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
        result_rgb = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)
        
        # í™”ë©´ í‘œì‹œ
        plt.figure(figsize=(15, 7))
        
        plt.subplot(1, 2, 1)
        plt.imshow(original_rgb)
        plt.title(f'ì›ë³¸: {title}', fontsize=12)
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.imshow(result_rgb)
        plt.title(f'ì°¨ì„  ì„¸ê·¸ë©˜í…Œì´ì…˜ (íŒŒë€ìƒ‰): {title}', fontsize=12)
        plt.axis('off')
        
        plt.tight_layout()
        
    def display_result_cv2(self, original, result, title):
        """
        OpenCVë¥¼ ì‚¬ìš©í•œ ë” ë¹ ë¥¸ ì´ë¯¸ì§€ í‘œì‹œ (í‚¤ ì…ë ¥ ëŒ€ê¸°)
        
        Args:
            original (np.array): ì›ë³¸ ì´ë¯¸ì§€
            result (np.array): ì²˜ë¦¬ëœ ì´ë¯¸ì§€
            title (str): ì œëª©
        """
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (í™”ë©´ì— ë§ê²Œ)
        height, width = original.shape[:2]
        max_height = 600
        if height > max_height:
            scale = max_height / height
            new_width = int(width * scale)
            new_height = int(height * scale)
            original = cv2.resize(original, (new_width, new_height))
            result = cv2.resize(result, (new_width, new_height))
        
        # ì´ë¯¸ì§€ë¥¼ ë‚˜ë€íˆ ë°°ì¹˜
        combined = np.hstack([original, result])
        
        # í…ìŠ¤íŠ¸ ì¶”ê°€
        cv2.putText(combined, f'Original: {title}', (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(combined, f'Blue Segmented: {title}', (original.shape[1] + 10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        # í•˜ë‹¨ì— ì•ˆë‚´ ë©”ì‹œì§€
        cv2.putText(combined, 'Press any key for next image, ESC to exit', 
                   (10, combined.shape[0] - 10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # ì°½ í‘œì‹œ
        cv2.imshow('Lane Segmentation Results (Blue)', combined)
        
        # í‚¤ ì…ë ¥ ëŒ€ê¸°
        print(f"ğŸ‘† {title} - ì•„ë¬´ í‚¤ë‚˜ ëˆ„ë¥´ë©´ ë‹¤ìŒ ì´ë¯¸ì§€ë¡œ... (ESCë¡œ ì¢…ë£Œ)")
        key = cv2.waitKey(0) & 0xFF
        
        return key == 27  # ESC í‚¤ í™•ì¸ (ì¢…ë£Œ ì‹ í˜¸)
    
    def process_all_images(self, max_images=None, save_results=True, show_results=True, use_cv2=True):
        """
        í…ŒìŠ¤íŠ¸ í´ë”ì˜ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬
        
        Args:
            max_images (int): ì²˜ë¦¬í•  ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ (Noneì´ë©´ ì „ì²´)
            save_results (bool): ê²°ê³¼ ì €ì¥ ì—¬ë¶€
            show_results (bool): ê²°ê³¼ í™”ë©´ í‘œì‹œ ì—¬ë¶€
            use_cv2 (bool): OpenCV ì‚¬ìš© ì—¬ë¶€ (ë¹ ë¥¸ í‚¤ ì…ë ¥ ì‘ë‹µ)
        """
        image_files = self.get_test_images()
        
        if not image_files:
            print("âŒ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        if max_images:
            image_files = image_files[:max_images]
        
        print(f"\nğŸš€ ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œì‘: {len(image_files)}ê°œ")
        print("=" * 60)
        
        if use_cv2 and show_results:
            print("ğŸ’¡ ì¡°ì‘ë²•:")
            print("   - ì•„ë¬´ í‚¤: ë‹¤ìŒ ì´ë¯¸ì§€")
            print("   - ESC: ì¢…ë£Œ")
            print("=" * 60)
        
        processed_count = 0
        try:
            for i, image_path in enumerate(image_files, 1):
                try:
                    print(f"\n[{i}/{len(image_files)}]", end=" ")
                    result, should_exit = self.process_single_image(
                        image_path, 
                        save_result=save_results,
                        show_result=show_results,
                        use_cv2=use_cv2
                    )
                    
                    if result is not None:
                        processed_count += 1
                    
                    # ESCë¡œ ì¢…ë£Œ
                    if should_exit:
                        print("\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.")
                        break
                        
                except Exception as e:
                    print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    continue
        
        finally:
            if use_cv2:
                cv2.destroyAllWindows()  # ëª¨ë“  OpenCV ì°½ ë‹«ê¸°
        
        print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ: {processed_count}/{len(image_files)}ê°œ ì„±ê³µ")
    
    def process_video(self, video_path, output_path=None, show_live=True):
        """
        ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬ (ë³´ë„ˆìŠ¤ ê¸°ëŠ¥)
        
        Args:
            video_path (str): ì…ë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            output_path (str): ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
            show_live (bool): ì‹¤ì‹œê°„ í‘œì‹œ ì—¬ë¶€
        """
        if not os.path.exists(video_path):
            print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")
            return
        
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print("âŒ ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ë¹„ë””ì˜¤ ì†ì„± ê°€ì ¸ì˜¤ê¸°
        fps = int(cap.get(cv2.CAP_PROP_FPS))
        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        print(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {width}x{height}, {fps}fps, {total_frames}í”„ë ˆì„")
        
        # ì¶œë ¥ ë¹„ë””ì˜¤ ì„¤ì •
        if output_path:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
        
        frame_count = 0
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                frame_count += 1
                
                # ëª¨ë¸ ì¶”ë¡ 
                results = self.model(frame, conf=0.25, verbose=False)
                
                if results and results[0].masks:
                    masks = results[0].masks.data.cpu().numpy()
                    
                    # ë§ˆìŠ¤í¬ í•©ì¹˜ê¸°
                    combined_mask = np.zeros((height, width), dtype=np.uint8)
                    for mask in masks:
                        mask_resized = cv2.resize(mask, (width, height))
                        mask_binary = (mask_resized > 0.5).astype(np.uint8) * 255
                        combined_mask = cv2.bitwise_or(combined_mask, mask_binary)
                    
                    # íŒŒë€ìƒ‰ ì˜¤ë²„ë ˆì´ ì ìš©
                    frame = self.create_blue_overlay(frame, combined_mask)
                
                # ê²°ê³¼ ì €ì¥
                if output_path:
                    out.write(frame)
                
                # ì‹¤ì‹œê°„ í‘œì‹œ
                if show_live:
                    cv2.imshow('Lane Segmentation', frame)
                    if cv2.waitKey(1) & 0xFF == ord('q'):
                        break
                
                # ì§„í–‰ ìƒí™© í‘œì‹œ
                if frame_count % 30 == 0:
                    print(f"ì²˜ë¦¬ ì¤‘: {frame_count}/{total_frames} í”„ë ˆì„")
        
        finally:
            cap.release()
            if output_path:
                out.release()
            cv2.destroyAllWindows()
        
        print(f"ğŸ‰ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì™„ë£Œ: {frame_count}í”„ë ˆì„")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ê²½ë¡œ ì„¤ì •
    BASE_PATH = r"C:\Project\DSS\AI_Academy\yolov8"
    MODEL_PATH = os.path.join(BASE_PATH, "DSS_AI_training", "DSS_experiment_1", "weights", "best.pt")
    TEST_FOLDER = os.path.join(BASE_PATH, "dataset", "test", "images")
    
    print("=" * 60)
    print("ğŸ¯ YOLOv8 ì°¨ì„  ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¶”ë¡  ì‹œìŠ¤í…œ (íŒŒë€ìƒ‰ í‘œì‹œ)")
    print("=" * 60)
    print(f"ğŸ“‚ ëª¨ë¸ ê²½ë¡œ: {MODEL_PATH}")
    print(f"ğŸ“ í…ŒìŠ¤íŠ¸ í´ë”: {TEST_FOLDER}")
    print("=" * 60)
    
    # ê²½ë¡œ í™•ì¸
    if not os.path.exists(MODEL_PATH):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {MODEL_PATH}")
        print("í›ˆë ¨ì´ ì™„ë£Œëœ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        return
    
    if not os.path.exists(TEST_FOLDER):
        print(f"âŒ í…ŒìŠ¤íŠ¸ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {TEST_FOLDER}")
        return
    
    try:
        # ì¶”ë¡  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        inference = YOLOv8SegmentationInference(MODEL_PATH, TEST_FOLDER)
        
        # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì²˜ë¦¬ (OpenCV ì‚¬ìš© - ë¹ ë¥¸ í‚¤ ì…ë ¥)
        inference.process_all_images(
            max_images=10,      # ì²˜ìŒ 10ê°œ ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬ (ì „ì²´ëŠ” None)
            save_results=True,  # ê²°ê³¼ ì €ì¥
            show_results=True,  # í™”ë©´ í‘œì‹œ
            use_cv2=True        # OpenCV ì‚¬ìš© (ë¹ ë¥¸ í‚¤ ì…ë ¥ ì‘ë‹µ)
        )
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

if __name__ == "__main__":
    main()

# ===== ì‚¬ìš© ì˜ˆì‹œ =====
"""
# 1. ê¸°ë³¸ ì‚¬ìš©ë²•
python yolov8_inference.py

# 2. ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬
inference = YOLOv8SegmentationInference(model_path, test_folder)
inference.process_single_image("path/to/image.jpg")

# 3. ë¹„ë””ì˜¤ ì²˜ë¦¬ (ë³´ë„ˆìŠ¤)
inference.process_video("input_video.mp4", "output_video.mp4")

# 4. ìƒ‰ìƒ ë³€ê²½í•˜ê³  ì‹¶ë‹¤ë©´:
# create_blue_overlay í•¨ìˆ˜ì—ì„œ blue_color ê°’ì„ ë³€ê²½
# ì˜ˆ: (0, 255, 0) = ì´ˆë¡ìƒ‰, (0, 0, 255) = ë¹¨ê°„ìƒ‰, (255, 255, 0) = ì‹œì•ˆìƒ‰
"""