# yolov8_custom_train.py
# 640x 480 image í•™ìŠµìš©

import os
import zipfile
import yaml
import shutil
import random
from pathlib import Path
from ultralytics import YOLO
import torch

class YOLOv8Trainer:
    def __init__(self, zip_path, extract_path="./dataset"):
        """
        YOLOv8 í›ˆë ¨ì„ ìœ„í•œ í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            zip_path (str): Roboflowì—ì„œ ë‹¤ìš´ë°›ì€ zip íŒŒì¼ ê²½ë¡œ
            extract_path (str): ë°ì´í„°ì…‹ì„ ì••ì¶• í•´ì œí•  ê²½ë¡œ
        """
        self.zip_path = zip_path
        self.extract_path = extract_path
        self.dataset_path = None
        self.yaml_path = None
        
    def extract_dataset(self):
        """Roboflow zip íŒŒì¼ ì••ì¶• í•´ì œ"""
        print("ë°ì´í„°ì…‹ ì••ì¶• í•´ì œ ì¤‘...")
        
        # ì••ì¶• í•´ì œ ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(self.extract_path, exist_ok=True)
        
        # zip íŒŒì¼ ì••ì¶• í•´ì œ
        with zipfile.ZipFile(self.zip_path, 'r') as zip_ref:
            zip_ref.extractall(self.extract_path)
        
        print(f"ë°ì´í„°ì…‹ì´ {self.extract_path}ì— ì••ì¶• í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # data.yaml íŒŒì¼ ì°¾ê¸°
        for root, dirs, files in os.walk(self.extract_path):
            if 'data.yaml' in files:
                self.yaml_path = os.path.join(root, 'data.yaml')
                self.dataset_path = root
                break
        
        if not self.yaml_path:
            raise FileNotFoundError("data.yaml íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        print(f"data.yaml íŒŒì¼ ìœ„ì¹˜: {self.yaml_path}")
        return self.yaml_path
    
    def check_dataset_structure(self):
        """ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸ ë° ìë™ ìˆ˜ì •"""
        print("\n=== ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸ ===")
        
        with open(self.yaml_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        print(f"í´ë˜ìŠ¤ ìˆ˜: {data.get('nc', 'Unknown')}")
        print(f"í´ë˜ìŠ¤ ì´ë¦„: {data.get('names', 'Unknown')}")
        
        # ì‹¤ì œ í´ë” êµ¬ì¡° í™•ì¸
        print(f"\nì‹¤ì œ í´ë” êµ¬ì¡°:")
        for item in os.listdir(self.dataset_path):
            item_path = os.path.join(self.dataset_path, item)
            if os.path.isdir(item_path):
                print(f"  ğŸ“ {item}/")
                # í•˜ìœ„ í´ë” í™•ì¸
                try:
                    sub_items = os.listdir(item_path)
                    for sub_item in sub_items:
                        sub_path = os.path.join(item_path, sub_item)
                        if os.path.isdir(sub_path):
                            img_count = len([f for f in os.listdir(sub_path) 
                                           if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
                            print(f"    ğŸ“ {sub_item}/ ({img_count}ê°œ ì´ë¯¸ì§€)")
                except:
                    pass
        
        # ì´ë¯¸ì§€ ê°œìˆ˜ í™•ì¸ ë° í´ë”ëª… ë§¤í•‘
        folder_mapping = {}
        
        # ê°€ëŠ¥í•œ í´ë”ëª…ë“¤ í™•ì¸
        possible_folders = ['train', 'val', 'valid', 'validation', 'test']
        actual_folders = [f for f in os.listdir(self.dataset_path) 
                         if os.path.isdir(os.path.join(self.dataset_path, f))]
        
        print(f"\nğŸ“‚ ë°œê²¬ëœ í´ë”ë“¤: {actual_folders}")
        
        # í´ë”ëª… ë§¤í•‘ ìƒì„±
        for folder in actual_folders:
            if 'train' in folder.lower():
                folder_mapping['train'] = folder
            elif any(val_name in folder.lower() for val_name in ['val', 'valid']):
                folder_mapping['val'] = folder
            elif 'test' in folder.lower():
                folder_mapping['test'] = folder
        
        print(f"ğŸ“‹ í´ë” ë§¤í•‘: {folder_mapping}")
        
        # ê° í´ë”ì˜ ì´ë¯¸ì§€ ê°œìˆ˜ í™•ì¸
        for standard_name, actual_name in folder_mapping.items():
            images_path = os.path.join(self.dataset_path, actual_name, 'images')
            if os.path.exists(images_path):
                img_count = len([f for f in os.listdir(images_path) 
                               if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
                print(f"âœ… {standard_name} ({actual_name}): {img_count}ê°œ ì´ë¯¸ì§€")
            else:
                print(f"âŒ {standard_name} ({actual_name}): images í´ë” ì—†ìŒ")
        
        return folder_mapping
    
    def copy_train_to_valid_test(self):
        """
        train í´ë”ì˜ ëª¨ë“  ë°ì´í„°ë¥¼ validì™€ test í´ë”ì— ë³µì‚¬
        (ë¶„í• í•˜ì§€ ì•Šê³  ì „ì²´ ë°ì´í„°ë¥¼ ê° í´ë”ì— ë³µì‚¬)
        """
        print(f"\n=== Train ë°ì´í„°ë¥¼ Valid/Testë¡œ ë³µì‚¬ ===")
        
        train_images_path = os.path.join(self.dataset_path, 'train', 'images')
        train_labels_path = os.path.join(self.dataset_path, 'train', 'labels')
        
        if not os.path.exists(train_images_path):
            raise FileNotFoundError(f"Train images í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_images_path}")
        
        # ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        image_files = [f for f in os.listdir(train_images_path) 
                      if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        
        if len(image_files) == 0:
            raise ValueError("Train í´ë”ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤!")
        
        print(f"ğŸ“ ë³µì‚¬í•  ì´ë¯¸ì§€ ìˆ˜: {len(image_files)}ê°œ")
        
        # validì™€ test í´ë”ì— ì „ì²´ ë°ì´í„° ë³µì‚¬
        folders_to_create = ['valid', 'test']
        
        for folder_name in folders_to_create:
            # í´ë” ìƒì„±
            folder_images_path = os.path.join(self.dataset_path, folder_name, 'images')
            folder_labels_path = os.path.join(self.dataset_path, folder_name, 'labels')
            
            os.makedirs(folder_images_path, exist_ok=True)
            os.makedirs(folder_labels_path, exist_ok=True)
            
            print(f"ğŸ“‚ {folder_name} í´ë”ì— ë°ì´í„° ë³µì‚¬ ì¤‘...")
            
            # ëª¨ë“  íŒŒì¼ ë³µì‚¬
            for filename in image_files:
                # ì´ë¯¸ì§€ íŒŒì¼ ë³µì‚¬
                src_img = os.path.join(train_images_path, filename)
                dst_img = os.path.join(folder_images_path, filename)
                shutil.copy2(src_img, dst_img)
                
                # ë¼ë²¨ íŒŒì¼ ë³µì‚¬ (ìˆëŠ” ê²½ìš°)
                label_filename = os.path.splitext(filename)[0] + '.txt'
                src_label = os.path.join(train_labels_path, label_filename)
                dst_label = os.path.join(folder_labels_path, label_filename)
                
                if os.path.exists(src_label):
                    shutil.copy2(src_label, dst_label)
            
            print(f"âœ… {folder_name} í´ë” ë³µì‚¬ ì™„ë£Œ: {len(image_files)}ê°œ íŒŒì¼")
        
        print(f"ğŸ‰ Train ë°ì´í„° ë³µì‚¬ ì™„ë£Œ!")
        print(f"ğŸ“ Train: {len(image_files)}ê°œ")
        print(f"ğŸ“ Valid: {len(image_files)}ê°œ (Trainê³¼ ë™ì¼)")
        print(f"ğŸ“ Test: {len(image_files)}ê°œ (Trainê³¼ ë™ì¼)")
        
        return {
            'train': len(image_files),
            'valid': len(image_files),
            'test': len(image_files)
        }
    
    def convert_segmentation_to_detection_labels(self):
        """
        ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¼ë²¨ì„ ê°ì²´ ê°ì§€ìš© ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ë³€í™˜
        """
        print(f"\n=== ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¼ë²¨ì„ ê°ì²´ ê°ì§€ìš©ìœ¼ë¡œ ë³€í™˜ ===")
        
        folders = ['train', 'valid', 'test']
        converted_count = 0
        
        for folder in folders:
            labels_path = os.path.join(self.dataset_path, folder, 'labels')
            if not os.path.exists(labels_path):
                continue
                
            print(f"ğŸ“ {folder} í´ë” ì²˜ë¦¬ ì¤‘...")
            
            for label_file in os.listdir(labels_path):
                if not label_file.endswith('.txt'):
                    continue
                    
                file_path = os.path.join(labels_path, label_file)
                
                with open(file_path, 'r') as f:
                    lines = f.readlines()
                
                new_lines = []
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) < 3:  # ìµœì†Œ í´ë˜ìŠ¤ + 2ê°œ ì¢Œí‘œ
                        continue
                        
                    class_id = parts[0]
                    
                    # ì¢Œí‘œë“¤ ì¶”ì¶œ (í´ë˜ìŠ¤ ì œì™¸)
                    coords = [float(x) for x in parts[1:]]
                    
                    if len(coords) % 2 != 0:  # x,y ìŒì´ ì•„ë‹Œ ê²½ìš°
                        coords = coords[:-1]  # ë§ˆì§€ë§‰ í•˜ë‚˜ ì œê±°
                    
                    # x, y ì¢Œí‘œ ë¶„ë¦¬
                    x_coords = coords[::2]  # ì§ìˆ˜ ì¸ë±ìŠ¤ (x)
                    y_coords = coords[1::2]  # í™€ìˆ˜ ì¸ë±ìŠ¤ (y)
                    
                    if len(x_coords) < 2:
                        continue
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
                    x_min, x_max = min(x_coords), max(x_coords)
                    y_min, y_max = min(y_coords), max(y_coords)
                    
                    # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (center_x, center_y, width, height)
                    center_x = (x_min + x_max) / 2
                    center_y = (y_min + y_max) / 2
                    width = x_max - x_min
                    height = y_max - y_min
                    
                    # ìƒˆ ë¼ë²¨ ë¼ì¸ ìƒì„±
                    new_line = f"{class_id} {center_x:.6f} {center_y:.6f} {width:.6f} {height:.6f}\n"
                    new_lines.append(new_line)
                
                # ë³€í™˜ëœ ë¼ë²¨ ì €ì¥
                if new_lines:
                    with open(file_path, 'w') as f:
                        f.writelines(new_lines)
                    converted_count += 1
        
        print(f"âœ… ë¼ë²¨ ë³€í™˜ ì™„ë£Œ: {converted_count}ê°œ íŒŒì¼")
        return converted_count
    
    def update_yaml_paths(self, folder_mapping=None):
        """data.yamlì˜ ê²½ë¡œë¥¼ ì ˆëŒ€ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸ (í´ë”ëª… ìë™ ë§¤í•‘)"""
        with open(self.yaml_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)
        
        # ì ˆëŒ€ ê²½ë¡œë¡œ ì—…ë°ì´íŠ¸
        base_path = Path(self.dataset_path).absolute()
        
        if folder_mapping:
            # ì‹¤ì œ í´ë”ëª…ìœ¼ë¡œ ë§¤í•‘
            if 'train' in folder_mapping:
                data['train'] = str(base_path / folder_mapping['train'] / 'images')
                print(f"âœ… train ê²½ë¡œ: {data['train']}")
            
            if 'val' in folder_mapping:
                data['val'] = str(base_path / folder_mapping['val'] / 'images')
                print(f"âœ… val ê²½ë¡œ: {data['val']}")
            
            if 'test' in folder_mapping:
                data['test'] = str(base_path / folder_mapping['test'] / 'images')
                print(f"âœ… test ê²½ë¡œ: {data['test']}")
        else:
            # ê¸°ë³¸ í´ë”ëª… ì‚¬ìš©
            data['train'] = str(base_path / 'train' / 'images')
            data['val'] = str(base_path / 'valid' / 'images')
            
            if os.path.exists(base_path / 'test' / 'images'):
                data['test'] = str(base_path / 'test' / 'images')
        
        # ì—…ë°ì´íŠ¸ëœ yaml ì €ì¥
        with open(self.yaml_path, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False)
        
        print("âœ… data.yaml ê²½ë¡œê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ì—…ë°ì´íŠ¸ëœ ë‚´ìš© í™•ì¸
        print(f"\nğŸ“„ ì—…ë°ì´íŠ¸ëœ data.yaml ë‚´ìš©:")
        with open(self.yaml_path, 'r', encoding='utf-8') as f:
            content = f.read()
            print(content)
    
    def train_model(self, 
                   model_size='yolov8n',
                   epochs=100,
                   img_size=640,
                   batch_size=16,
                   device='auto',
                   project='yolov8_training',
                   name='exp'):
        """
        YOLOv8 ëª¨ë¸ í›ˆë ¨
        
        Args:
            model_size (str): ëª¨ë¸ í¬ê¸° ('yolov8n', 'yolov8s', 'yolov8m', 'yolov8l', 'yolov8x')
            epochs (int): í›ˆë ¨ ì—í¬í¬ ìˆ˜
            img_size (int): ì´ë¯¸ì§€ í¬ê¸°
            batch_size (int): ë°°ì¹˜ í¬ê¸°
            device (str): ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ ('auto', 'cpu', 'cuda', '0', '1', etc.)
            project (str): í”„ë¡œì íŠ¸ í´ë” ì´ë¦„
            name (str): ì‹¤í—˜ ì´ë¦„
        """
        print(f"\n=== YOLOv8 í›ˆë ¨ ì‹œì‘ ===")
        print(f"ëª¨ë¸: {model_size}")
        print(f"ì—í¬í¬: {epochs}")
        print(f"ì´ë¯¸ì§€ í¬ê¸°: {img_size}")
        print(f"ë°°ì¹˜ í¬ê¸°: {batch_size}")
        print(f"ìš”ì²­ ë””ë°”ì´ìŠ¤: {device}")
        
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ ìƒì„¸ í™•ì¸
        print(f"\nğŸ” GPU ìƒíƒœ í™•ì¸:")
        print(f"PyTorch ë²„ì „: {torch.__version__}")
        print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"CUDA ë²„ì „: {torch.version.cuda}")
            print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")
            for i in range(torch.cuda.device_count()):
                print(f"GPU {i}: {torch.cuda.get_device_name(i)}")
                print(f"GPU {i} ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(i).total_memory / 1024**3:.1f}GB")
        else:
            print("âŒ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            print("GPU ë“œë¼ì´ë²„ì™€ CUDA ì„¤ì¹˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì • (GPU ìš°ì„  ì‚¬ìš©)
        if device == 'auto':
            if torch.cuda.is_available():
                device = '0'  # ì²« ë²ˆì§¸ GPU ì‚¬ìš©
                print(f"âœ… GPU ì‚¬ìš©: cuda:{device}")
            else:
                device = 'cpu'
                print(f"âš ï¸  CPU ì‚¬ìš© (GPU ì—†ìŒ)")
        else:
            print(f"âœ… ì§€ì •ëœ ë””ë°”ì´ìŠ¤ ì‚¬ìš©: {device}")
        
        # GPU ë©”ëª¨ë¦¬ í™•ì¸ ë° ë°°ì¹˜ í¬ê¸° ì¡°ì •
        if device != 'cpu' and torch.cuda.is_available():
            try:
                # GPU ë©”ëª¨ë¦¬ ì •ë³´
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
                print(f"ğŸ“Š GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
                
                # ë©”ëª¨ë¦¬ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ê¶Œì¥
                if gpu_memory < 4:
                    recommended_batch = 8
                elif gpu_memory < 8:
                    recommended_batch = 16
                elif gpu_memory < 12:
                    recommended_batch = 32
                else:
                    recommended_batch = 64
                
                if batch_size > recommended_batch:
                    print(f"âš ï¸  ë°°ì¹˜ í¬ê¸°ê°€ í½ë‹ˆë‹¤. ê¶Œì¥: {recommended_batch} (í˜„ì¬: {batch_size})")
                    print(f"ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ë³´ì„¸ìš”.")
                
            except Exception as e:
                print(f"GPU ë©”ëª¨ë¦¬ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        # ëª¨ë¸ ë¡œë“œ (ì‚¬ì „ í›ˆë ¨ëœ ê°€ì¤‘ì¹˜ ì‚¬ìš©)
        print(f"\nğŸ“¥ ëª¨ë¸ ë¡œë“œ ì¤‘: {model_size}.pt")
        model = YOLO(f'{model_size}.pt')
        
        # ëª¨ë¸ì„ ëª…ì‹œì ìœ¼ë¡œ GPUë¡œ ì´ë™
        if device != 'cpu' and torch.cuda.is_available():
            try:
                model.model = model.model.to(f'cuda:{device}' if device.isdigit() else device)
                print(f"âœ… ëª¨ë¸ì„ GPUë¡œ ì´ë™: {device}")
            except Exception as e:
                print(f"âš ï¸  GPU ì´ë™ ì‹¤íŒ¨: {e}")
                device = 'cpu'
        
        # í›ˆë ¨ ì‹œì‘
        print(f"\nğŸš€ í›ˆë ¨ ì‹œì‘ - ë””ë°”ì´ìŠ¤: {device}")
        results = model.train(
            data=self.yaml_path,
            epochs=epochs,
            imgsz=img_size,
            batch=batch_size,
            device=device,
            project=project,
            name=name,
            save=True,
            save_period=10,  # 10 ì—í¬í¬ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
            val=True,
            plots=True,
            verbose=True,
            # GPU ìµœì í™” ì„¤ì •
            amp=True,        # Automatic Mixed Precision (GPU ê°€ì†)
            cache=False,     # ë©”ëª¨ë¦¬ ì ˆì•½
            workers=8 if device != 'cpu' else 4,  # ë°ì´í„° ë¡œë” ì›Œì»¤ ìˆ˜
        )
        
        print(f"\nğŸ‰ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ ê²°ê³¼ í´ë”: {project}/{name}")
        print(f"ğŸ¤– ìµœì¢… ë””ë°”ì´ìŠ¤: {device}")
        
        return results
    
    def validate_model(self, model_path, project='yolov8_validation', name='exp'):
        """í›ˆë ¨ëœ ëª¨ë¸ ê²€ì¦"""
        print(f"\n=== ëª¨ë¸ ê²€ì¦ ì‹œì‘ ===")
        
        model = YOLO(model_path)
        results = model.val(
            data=self.yaml_path,
            project=project,
            name=name,
            save_json=True,
            plots=True
        )
        
        print("ê²€ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return results
    
    def predict_sample(self, model_path, image_path, conf=0.25, save=True):
        """ìƒ˜í”Œ ì´ë¯¸ì§€ë¡œ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"""
        print(f"\n=== ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ===")
        
        model = YOLO(model_path)
        results = model.predict(
            source=image_path,
            conf=conf,
            save=save,
            show_labels=True,
            show_conf=True
        )
        
        print("ì˜ˆì¸¡ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ì„¤ì •
    BASE_PATH = r"C:\Project\DSS\AI_Academy\yolov8"
    ZIP_PATH = os.path.join(BASE_PATH, "DSS_AI.v1i.yolov8.zip")
    EXTRACT_PATH = os.path.join(BASE_PATH, "dataset")
    
    # ê²½ë¡œ í™•ì¸
    if not os.path.exists(ZIP_PATH):
        print(f"âŒ ZIP íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {ZIP_PATH}")
        print("íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    print(f"âœ… ZIP íŒŒì¼ í™•ì¸ë¨: {ZIP_PATH}")
    
    # YOLOv8 í›ˆë ¨ê¸° ì´ˆê¸°í™”
    trainer = YOLOv8Trainer(ZIP_PATH, EXTRACT_PATH)
    
    try:
        # 1. ë°ì´í„°ì…‹ ì••ì¶• í•´ì œ
        trainer.extract_dataset()
        
        # 2. ë°ì´í„°ì…‹ êµ¬ì¡° í™•ì¸
        folder_mapping = trainer.check_dataset_structure()
        
        # 2-1. train í´ë”ë§Œ ìˆëŠ” ê²½ìš° ë°ì´í„° ë³µì‚¬
        if 'val' not in folder_mapping and 'test' not in folder_mapping:
            print("\nâš ï¸  Valid/Test í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. Train ë°ì´í„°ë¥¼ ë³µì‚¬í•©ë‹ˆë‹¤.")
            copy_result = trainer.copy_train_to_valid_test()
            
            # ë³µì‚¬ í›„ ë‹¤ì‹œ í´ë” êµ¬ì¡° í™•ì¸
            folder_mapping = trainer.check_dataset_structure()
        
        # 3. YAML ê²½ë¡œ ì—…ë°ì´íŠ¸ (í´ë”ëª… ìë™ ë§¤í•‘)
        trainer.update_yaml_paths(folder_mapping)
        
        # 4. ëª¨ë¸ í›ˆë ¨ (ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ - ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ ëŒ€ë¹„)
        try:
            # ë¨¼ì € yolov8n-seg ì‹œë„
            model_name = 'yolov8n-seg'
            results = trainer.train_model(
                model_size=model_name,
                epochs=1000,            
                img_size=(640,480),
                batch_size=64,
                device='0',            
                project=os.path.join(BASE_PATH, 'DSS_AI_training'),
                name='DSS_experiment_1'
            )
        except Exception as seg_error:
            print(f"âš ï¸  ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {seg_error}")
            print("ğŸ”„ ê¸°ë³¸ ê°ì²´ ê°ì§€ ëª¨ë¸ë¡œ ì‹œë„í•©ë‹ˆë‹¤...")
            
            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ëª¨ë¸ë¡œ í´ë°±
            model_name = 'yolov8n'
            results = trainer.train_model(
                model_size=model_name,
                epochs=100,            
                img_size=640,
                batch_size=32,
                device='0',            
                project=os.path.join(BASE_PATH, 'DSS_AI_training'),
                name='DSS_experiment_1_detection'
            )
        
        # 5. ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ê²€ì¦
        best_model_path = os.path.join(BASE_PATH, 'DSS_AI_training', 'DSS_experiment_1', 'weights', 'best.pt')
        trainer.validate_model(best_model_path, 
                             project=os.path.join(BASE_PATH, 'DSS_AI_validation'),
                             name='DSS_validation_1')
        
        # 6. ìƒ˜í”Œ ì˜ˆì¸¡ (ì„ íƒì‚¬í•­)
        # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ê°€ ìˆë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ê³  ê²½ë¡œë¥¼ ì„¤ì •í•˜ì„¸ìš”
        # sample_image = os.path.join(EXTRACT_PATH, "test", "images", "sample.jpg")
        # if os.path.exists(sample_image):
        #     trainer.predict_sample(best_model_path, sample_image)
        
        print("\nğŸ‰ DSS AI ëª¨ë¸ í›ˆë ¨ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ í”„ë¡œì íŠ¸ í´ë”: {BASE_PATH}")
        print(f"ğŸ¤– ìµœì¢… ëª¨ë¸: {best_model_path}")
        print(f"ğŸ“Š í›ˆë ¨ ê²°ê³¼: {os.path.join(BASE_PATH, 'DSS_AI_training', 'DSS_experiment_1')}")
        print(f"ğŸ“ˆ ê²€ì¦ ê²°ê³¼: {os.path.join(BASE_PATH, 'DSS_AI_validation', 'DSS_validation_1')}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
        print("ì˜¤ë¥˜ í•´ê²°ì„ ìœ„í•œ í™•ì¸ì‚¬í•­:")
        print("1. ZIP íŒŒì¼ ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸")
        print("2. ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ì´ ìˆëŠ”ì§€ í™•ì¸")
        print("3. í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸")

if __name__ == "__main__":
    # í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì•ˆë‚´
    print("=" * 60)
    print("ğŸš€ DSS AI Academy YOLOv8 í›ˆë ¨ ì‹œìŠ¤í…œ")
    print("=" * 60)
    print("ğŸ“‹ í•„ìš”í•œ íŒ¨í‚¤ì§€:")
    print("   pip install ultralytics")
    print("   pip install torch torchvision")
    print("   pip install PyYAML")
    print("\nğŸ“‚ í”„ë¡œì íŠ¸ ê²½ë¡œ: C:\\Project\\DSS\\AI_Academy\\yolov8")
    print("ğŸ“¦ ë°ì´í„°ì…‹: DSS_AI.v1i.yolov8.zip")
    print("=" * 60 + "\n")
    
    main()

# ===== DSS í”„ë¡œì íŠ¸ ì „ìš© ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ =====
# ===== DSS í”„ë¡œì íŠ¸ ì „ìš© ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ =====

def resume_dss_training(base_path=r"C:\Project\DSS\AI_Academy\yolov8", epochs=100):
    """DSS í”„ë¡œì íŠ¸ì˜ ì¤‘ë‹¨ëœ í›ˆë ¨ ì¬ê°œ"""
    checkpoint_path = os.path.join(base_path, 'DSS_AI_training', 'DSS_experiment_1', 'weights', 'last.pt')
    if os.path.exists(checkpoint_path):
        model = YOLO(checkpoint_path)
        results = model.train(resume=True, epochs=epochs)
        return results
    else:
        print(f"âŒ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        return None

def export_dss_model(base_path=r"C:\Project\DSS\AI_Academy\yolov8", format='onnx'):
    """DSS AI ëª¨ë¸ì„ ë‹¤ë¥¸ í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°"""
    model_path = os.path.join(base_path, 'DSS_AI_training', 'DSS_experiment_1', 'weights', 'best.pt')
    if os.path.exists(model_path):
        model = YOLO(model_path)
        model.export(format=format)
        print(f"âœ… DSS AI ëª¨ë¸ì´ {format} í˜•ì‹ìœ¼ë¡œ ë‚´ë³´ë‚´ì¡ŒìŠµë‹ˆë‹¤.")
        export_path = model_path.replace('.pt', f'.{format}')
        print(f"ğŸ“ ë‚´ë³´ë‚¸ íŒŒì¼: {export_path}")
    else:
        print(f"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")

def benchmark_dss_model(base_path=r"C:\Project\DSS\AI_Academy\yolov8"):
    """DSS AI ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    model_path = os.path.join(base_path, 'DSS_AI_training', 'DSS_experiment_1', 'weights', 'best.pt')
    if os.path.exists(model_path):
        model = YOLO(model_path)
        results = model.benchmark()
        return results
    else:
        print(f"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None

def predict_with_dss_model(image_path, base_path=r"C:\Project\DSS\AI_Academy\yolov8", conf=0.25):
    """DSS AI ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ì˜ˆì¸¡"""
    model_path = os.path.join(base_path, 'DSS_AI_training', 'DSS_experiment_1', 'weights', 'best.pt')
    if os.path.exists(model_path) and os.path.exists(image_path):
        model = YOLO(model_path)
        results = model.predict(
            source=image_path,
            conf=conf,
            save=True,
            project=os.path.join(base_path, 'DSS_predictions'),
            name='prediction_results'
        )
        print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ! ê²°ê³¼: {os.path.join(base_path, 'DSS_predictions', 'prediction_results')}")
        return results
    else:
        if not os.path.exists(model_path):
            print(f"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        if not os.path.exists(image_path):
            print(f"âŒ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
        return None